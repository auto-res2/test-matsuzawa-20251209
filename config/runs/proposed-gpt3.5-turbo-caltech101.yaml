run_id: proposed-gpt3.5-turbo-caltech101
method: RUA-BBPS
method_type: proposed
version: v1
summary: "RUA-BBPS run where the primary varied component is the proposer (gpt-3.5-turbo). VLM defaults to CLIP RN50. Runner-scale defaults applied."
model:
  name: "gpt-3.5-turbo"
  id: "gpt3.5-turbo"
  role: llm_proposer
  description: "Conversational LLM used to propose prompt templates; can be replaced by local/mock proposer for offline experiments."
components:
  evaluator:
    name: "CLIP RN50"
    id: "clip-rn50"
    role: vlm
    description: "Local evaluator returning top-1 accuracy on few-shot fold."
dataset:
  name: caltech101
  id: caltech101
  max_sampled_classes: 30
  splits:
    n_folds: 3
    shots: [1, 4]
    runner_scale: true
  preprocessing:
    image_size: 224
    center_crop: true
    normalize: true
training:
  nrestart: 5
  iterations_per_restart: 5
  proposals_per_iteration: 50
  top_k_pool: 10
  validation_budget_per_restart: 3
  learning_rate: 0.001
  batch_size: 16
  epochs: 1
  optimizer: adam
search_config:
  method: RUA-BBPS
  adjusted_score: "acc_train - lambda_len * LenNorm(prompt) - mu_sim * MinHashSimMax(prompt,TopKPool) - gamma_unc * BootstrapStd(prompt)"
  minhash:
    ngram_n: 3
    k_sig: 64
  bootstrap:
    B: 20
    sample_frac: 0.7
  length_normalization:
    max_len_tokens: 40
    default_lambda_len: 0.05
  semantic_penalty:
    default_mu_sim: 0.30
  uncertainty_penalty:
    default_gamma_unc: 0.50
  adaptive_updater:
    type: multiplicative_weights
    eta: 0.2
    grid: "small discrete grid of (lambda_len, mu_sim, gamma_unc) tuples (configured externally)"
    validation_budget_V_eval: 3
    update_period_iterations: 3
  pool_and_selection:
    top_k_for_similarity: 15
    selection_sort_key: adj_score
evaluation:
  primary_metric: "held-out top-1 accuracy"
optuna:
  n_trials: 0
  search_spaces: []
notes: "This variant explicitly tags gpt-3.5-turbo as the primary varied model for experiment bookkeeping; evaluation still uses CLIP RN50 as the VLM."
